{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daria-Lytvynenko/ML_course/blob/main/HW_2_2_%D0%9F%D0%BE%D0%BB%D1%96%D0%BD%D0%BE%D0%BC%D1%96%D0%B0%D0%BB%D1%8C%D0%BD%D1%96_%D0%BE%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми проведемо додаткові експерименти для рішення задачі бінарної класифікації і створимо ваш новий submission на змагання на Kaggle.\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "**Завдання 0**. Завантажте дані `train.csv`, `test.csv`, `sample_submission.csv` зі змагання на Kaggle [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/competitions/bank-customer-churn-prediction-dlu-course-c-2). Для завантаження потрібно долучитись до змагання (натиснути кнопку \"Join\").\n",
        "\n",
        "**Завдання 1**. **Збираємо весь код з попереднього ДЗ в одному місці.** В лекційному ноутбуці `Логістична регресія з ScikitLearn. Повна ML задача.ipynb` ми познайомились з поняттям пайплайнів, а також я показала, як компактно виглядає рішення МЛ задачі, якщо ми зберемо весь код разом.\n",
        "\n",
        "Оскільки ми далі будемо робити експерименти, які включають ті самі етапи попередньої обробки, але інше моделювання - буде зручно мати весь код компактно і під рукою. Тому зараз ми займемось збором коду до купи :) Після цього завдання для подальших експериментів ви можете перенести частини розвʼязку взагалі в окремий `.py` файл, аби було зручно імпортувати функції.\n",
        "\n",
        "Зі свого рішення в попередньому домашньому завданні (`Логістична регресія з scikit learn.ipynb`) зберіть усі кроки розвʼязку задачі разом з використанням `sklearn.Pipeline` за прикладом з лекції.\n",
        "\n",
        "Ваш код нижче має містити\n",
        "1. Читання даних з файлу (поза пайплайном).\n",
        "2. Розбиття на тренувальний і валідаційний набори, де валідаційний містить 20% даних (поза пайплайном).\n",
        "3. Виділення категоріальних і числових колонок (поза пайплайном).\n",
        "4. Підготовку категоріальних і числових колонок (частина пайплайну). В прикладі в лекції ми оформлювали обробку числових і категоріальних колонок в окремі трансформери `numeric_transformer`, `categorical_cols`. Рекоемндую зробити саме так, так потім зручніше вносити зміни :)\n",
        "5. Тренування лог регресії (частина пайплайну).\n",
        "6. Запуск пайплайну на тренування на трен. даних (поза пайплайном).\n",
        "7. Запуск пайплайну на передбачення на трен і вал. даних і вимір метрик якості ROC-AUC + вивдення Confusion Matrix (поза пайплайном).\n",
        "8. Збереження моделі в формат joblib (поза пайплайном).\n",
        "\n",
        "Ви це все вже зробили в попереднтьому ДЗ! Тож, тут просто заадча все зібрати разом.\n",
        "\n",
        "Нижче я додала підказки, що покроково ви маєте зробити. Якщо ви почуваєтесь впевнено, можете видалити ці підказки і реалізувати все самостійно, або ж - просто заповнити пропуски.\n",
        "\n",
        "Завдання оцінюється в 10 балів. Головний результат - аби код в фіналі був робочий. Бо за не робочий нам гроші ніхто не заплатить :)"
      ],
      "metadata": {
        "id": "gJ2A6t3mdEed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score, auc\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
        "import joblib\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_XbzEqgD3QKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv('drive/MeDrive/ML_course/train.csv', index_col=0)\n",
        "raw_df.drop(['Surname', 'CustomerId'], axis=1, inplace=True)\n",
        "\n",
        "train_df, val_df = train_test_split(raw_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Створюємо трен. і вал. набори\n",
        "input_cols = list(raw_df.columns)[0:-1]\n",
        "target_col = list(raw_df.columns)[-1]\n",
        "train_inputs, train_targets = train_df[input_cols], train_df[target_col]\n",
        "val_inputs, val_targets = val_df[input_cols], val_df[target_col]\n",
        "\n",
        "# Виявляємо числові і категоріальні колонки\n",
        "numeric_cols = raw_df[input_cols].select_dtypes(exclude='object').columns.tolist()\n",
        "categorical_cols = raw_df[input_cols].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Створюємо трансформери для числових і категоріальних колонок\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler',  MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# Комбінуємо трансформери для різних типів колонок в один препроцесор\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Стоврюємо пайплайн, який спочатку запускає препроцесинг, потім тренуєм модель\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Тренуємо пайплайн\n",
        "model_pipeline.fit(train_inputs, train_targets)\n",
        "\n",
        "# Функція, щоб передбачати і рахувати метрики\n",
        "def predict_and_plot(model_pipeline, inputs, targets, name=''):\n",
        "    preds = model_pipeline.predict(inputs)\n",
        "    pred_proba=model_pipeline.predict_proba(inputs)\n",
        "    fpr, tpr, thresholds=roc_curve(targets, pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f\"Area under ROC score on {name} dataset: {roc_auc:.2f}%\")\n",
        "    confusion_matrix_ = confusion_matrix(targets, preds)\n",
        "    plt.figure()\n",
        "    sns.heatmap(confusion_matrix_, annot=True, cmap='Blues')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('Target')\n",
        "    plt.title('{} Confusion Matrix'.format(name))\n",
        "    plt.show()\n",
        "    return preds\n",
        "\n",
        "# Оцінюємо модель на трен і вал даних\n",
        "train_preds = predict_and_plot(model_pipeline, train_inputs, train_targets, name='train dataset')\n",
        "val_preds = predict_and_plot(model_pipeline, val_inputs, val_targets, name='validation dataset')\n",
        "\n",
        "# Зберігаємо модель для подальшого використання\n",
        "joblib.dump(model_pipeline, 'drive/MeDrive/ML_course/model_pipeline.joblib' )\n"
      ],
      "metadata": {
        "id": "0LZialdo4IPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 2**. Такс, у нас з вами є вже готовий пайплайн. Давайте проведемо нові експерименти.\n",
        "\n",
        "  Додайте в попередню обробку числових колонок генерацію polinomal features до степені 2 включно. Для цього створіть новий препроцесор і створіть новий пайплайн.\n",
        "\n",
        "  Запустіть пайплайн на тренування і виведіть метрики для тренувального і валідаційного набору. Напишіть, як вам модель? Чи спостерігається в цій моделі overfit чи underfit? Чи ця модель добре генералізує?"
      ],
      "metadata": {
        "id": "PXrc2NCa5lAK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjcmWMTOOjJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 3**. Тепер давайте створимо ще новий пайплайн, тільки тепер поліноміальні ознаки згенеруємо до степені 4. Зробіть висновок про якість моделі. Якщо вам подобається резульат якоїсь з моделей в цьому ДЗ - рекомендую зробити submission в змаганні."
      ],
      "metadata": {
        "id": "tkmEmHaP8Pen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsT-MDWuOkDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 4. Перенавчання і регуляризація**.\n",
        "\n",
        "  Скачайте набір даних `regression_data.csv`. Звичайте набір даних з `regression_data.csv`, розбийте на train і test (в тест 20%) і натренуйте модель лінійної регресії з масштабуванням числових ознак і поліноміальними ознаками до степені **5 включно**.\n",
        "\n",
        "  Виміряйте якість прогностичної моделі і зробіть висновок, чи модель хороша, чи вона добре генералізує?\n"
      ],
      "metadata": {
        "id": "ozN2ONZGCBS6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbl0jQ3WOlgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 5**. Натренуйте моделі Lasso(), Ridge(), ElasaticNet() на цих даних (з поліном ознаками до степені 20 включно), порівняйте якість з тою, яка була отримана з лінійною регресією. Яка модель найкраще генералізує і чому на ваш погляд (можливо треба буде для відповіді зробити додатковий аналіз ознак)?"
      ],
      "metadata": {
        "id": "JNUt-Q6UHkn7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y93ItPYdOnpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}